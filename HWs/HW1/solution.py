# -*- coding: utf-8 -*-
"""solution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b8V5zDdV2fvVm2mlYYFX77D1OWYwUYM3
"""

import numpy as np
# import random 
# import matplotlib.pyplot as plt
######## DO NOT MODIFY THIS FUNCTION ########
def draw_rand_label(x, label_list):
    seed = abs(np.sum(x))
    while seed < 1:
        seed = 10 * seed
    seed = int(1000000 * seed)
    np.random.seed(seed)
    return np.random.choice(label_list)
#############################################


class Q1:

    def feature_means(self, banknote):
        return [np.sum(banknote[:,i])/len(banknote[:,i]) for i in range(banknote.shape[1]-1)]

    def covariance_matrix(self, banknote):
        return np.cov(banknote[:, :-1].T)

    def feature_means_class_1(self, banknote):
        class1=np.array([banknote[i] for i in range(banknote.shape[0]) if banknote[i][-1]==1.0])
        return [np.sum(class1[:,i])/len(class1[:,i]) for i in range(class1.shape[1]-1)]

    def covariance_matrix_class_1(self, banknote):
        class1=np.array([banknote[i] for i in range(banknote.shape[0]) if banknote[i][-1]==1.0])
        return np.cov(class1[:, :-1].T)

class HardParzen:
    def __init__(self, h):
        self.h = h

    def train(self, train_inputs, train_labels):
        self.train_inputs = train_inputs
        self.train_labels = train_labels
        self.label_list=list(np.unique(train_labels))
        self.num_class = len(np.unique(train_labels))
    
    def euclidean_distances(self,x, Y):
      return (np.sum((np.abs(x - Y)) ** 2, axis=1)) ** (1.0 / 2)

    def compute_predictions(self, test_data):
        test_size = test_data.shape[0]
        counts = np.ones((test_size, self.num_class))
        classes_pred = np.zeros(test_size)
        for (i, ex) in enumerate(test_data):
            distances = self.euclidean_distances(ex, self.train_inputs) 
            neighbour_idx = []
            neighbour_idx = np.array([j for j in range(len(distances)) if distances[j] < self.h])
            if len(neighbour_idx)==0:
                output=draw_rand_label(ex,self.label_list)
                classes_pred[i]=output

            else:
              for k in neighbour_idx:
                counts[i, int(self.train_labels[k])] += 1          
              classes_pred[i] = np.argmax(counts[i, :])               

        return classes_pred


class SoftRBFParzen:
    def __init__(self, sigma):
        self.sigma  = sigma

    def train(self, train_inputs, train_labels):
        self.train_inputs = train_inputs
        self.train_labels = train_labels
        self.num_class = len(np.unique(train_labels))

    def euclidean_distances(self,x, Y):
      return (np.sum((np.abs(x - Y)) ** 2)) ** (1.0 / 2)
    
    def RBF(self,Xi, X, sigma):
        coef=((2*np.pi)**(len(Xi)/2))*(sigma**(len(Xi)))
        dist = self.euclidean_distances(X,Xi)**2
        return (1/coef)*np.exp((-1*dist)/(2*(sigma**2)))

    def compute_predictions(self, test_data):
        test_size = test_data.shape[0]
        counts = np.ones((test_size,self.num_class))
        classes_pred = np.zeros(test_size)

        for (i, ex) in enumerate(test_data):
          weights=[]
          summ=0
          for j in range(len(self.train_inputs)):
            wi=self.RBF(self.train_inputs[j],ex, self.sigma)
            counts[i, int(self.train_labels[j])]+=wi

          classes_pred[i] = np.argmax(counts[i, :])   
          
        return classes_pred


def split_dataset(banknote):
        train = [0,1,2,5]
        validation=[3]
        test=[4]

        train_cols = list(range(0,banknote.shape[1]-1))
        target_ind = [banknote.shape[1] - 1]

        inds = list(range(banknote.shape[0]))
        train_inds = [inds[i] for i in range(len(inds)) if inds[i]%5 in train]
        validation_inds = [inds[i] for i in range(len(inds)) if inds[i]%5 in validation]
        test_inds = [inds[i] for i in range(len(inds)) if inds[i]%5 in test]

        train_set = banknote[train_inds, :]
        train_set = train_set[:, train_cols + target_ind]
        test_set = banknote[test_inds, :]
        test_set = test_set[:, train_cols + target_ind]
        validation_set = banknote[validation_inds, :]
        validation_set = validation_set[:, train_cols + target_ind]

        return train_set, validation_set, test_set


class ErrorRate:
    def __init__(self, x_train, y_train, x_val, y_val):
        self.x_train = x_train
        self.y_train = y_train
        self.x_val = x_val
        self.y_val = y_val

    def hard_parzen(self, h):
        h_parzen = HardParzen(h)
        h_parzen.train(self.x_train, self.y_train)
        classes_pred_knn = h_parzen.compute_predictions(self.x_val)
        conf_mat = confusion_matrix(self.y_val, classes_pred_knn)
        total_num = np.sum(conf_mat)
        num_correct = np.sum(np.diag(conf_mat))
        return 1.0 - num_correct / total_num

    def soft_parzen(self, sigma):
        s_parzen = SoftRBFParzen(sigma)
        s_parzen.train(self.x_train, self.y_train.astype('int32') )
        classes_pred_knn = s_parzen.compute_predictions(self.x_val)
        conf_mat = confusion_matrix(self.y_val.astype('int32') , classes_pred_knn.astype('int32') )
        total_num = np.sum(conf_mat)
        num_correct = np.sum(np.diag(conf_mat))
        return 1.0 - num_correct / total_num


def confusion_matrix(true_labels, pred_labels):
    n_classes=2
    matrix = np.zeros((n_classes, n_classes))
    for (true, pred) in zip(true_labels, pred_labels):
        matrix[int(true), int(pred)] += 1
    return matrix

def get_test_errors(banknote):
    train_set, validation_set, test_set= split_dataset(banknote)
    ee=ErrorRate(train_set[:, :-1],train_set[:, -1].astype('int32'), test_set[:, :-1], test_set[:, -1].astype('int32') )
    errror_hard_parzen=ee.hard_parzen(3)
    errror_soft_parzen=ee.soft_parzen(0.5)
    return [errror_hard_parzen,errror_soft_parzen]


def random_projections(X, A):
    return np.dot(X,A)/np.sqrt(2)

